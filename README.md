#JMocap

JMocap allows you to load motion captured sessions of a single human motion recording and view it in 3D. Supported formats are Biovision (bvh) and Acclaim (asf+amc). The project is implemented in Java, using Java3D.

http://embots.dfki.de/img/jmocap-300.png

JMocap has been created by Michael Kipp during his time at DFKI Embodied Agents Research Group, Saarbr√ºcken, Germany (new affiliation: University of Applied Sciences Augsburg, Germany).

Motion trails have been added by Quan Nguyen, DFKI.

In the summer of 2013, a team of students at Augsburg University of Applied Sciences, namely Michael Christopher Hrstka, Levin Freiherr von Hollen and Franziska Zamponi extended the JMocap capabilities. They added single-person visualizations: movement/speed disk, tangential arrow and gesture space grid. And the following interpersonal visualizations: relativ speed, interpersonal distance (proxemic zones) and interpersonal angle/orientation. This has been published at LREC 2014:

Kipp, M., von Hollen, L., Hrstka, M.C., Zamponi, F. (2014) 
 Single-Person and Multi-Party 3D Visualizations for Nonverbal Communication Analysis]. In: Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC), ELDA, Paris.


http://michaelkipp.de/publication/Kippetal2014.pdf

http://michaelkipp.de/publication/kipp2014-poster.pdf

JMocap is also used as a library for the ANVIL video annotation tool to display motion capture data.
